{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "credit_defaults.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNSgR1Ds84a6PAmE5wrpFUk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikniksor/DataScience/blob/main/credit_defaults.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myb1u6OELDdc"
      },
      "source": [
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import scipy as sp\r\n",
        "import seaborn as sb\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "from sklearn import metrics\r\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaWhOZ_7MPpp"
      },
      "source": [
        "df = pd.read_csv(\"../data/dzSVM.csv\")\r\n",
        "# # Исследуем данные\r\n",
        "# Сколько классов? Объектов?\r\n",
        "n_samples, n_features = df.shape\r\n",
        "print(f\"Количество наблюдений: {n_samples}\")\r\n",
        "print(f\"Количество атрибутов: {n_features}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqesph0KMPvA"
      },
      "source": [
        "pd.set_option(\"display.max_columns\", None)\r\n",
        "print(\"Первые пять наблюдений: \")\r\n",
        "print(df.head())\r\n",
        "# Есть ли странности: столетние кредиты, возраст заемщика больше ста и т.д?\r\n",
        "print(\"Статистика по данным: \")\r\n",
        "print(df.describe(include=\"all\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ_tBGPZMP0m"
      },
      "source": [
        "plt.hist(df[~np.isnan(df[\"CLAGE\"])][\"CLAGE\"])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQhxFOshMP6Q"
      },
      "source": [
        "clage700orMore = df.CLAGE[df.CLAGE >= 700].count()\r\n",
        "print(\"%f процентов значений CLAGE >= 700 (кредит старше 58 лет), всего %i наблюдений\"\r\n",
        "      % ((clage700orMore/df.CLAGE.count())*100, clage700orMore))\r\n",
        "# Уберем эти наблюдения\r\n",
        "df.drop(df[df.CLAGE >= 700].index, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoSN3OqEMP_r"
      },
      "source": [
        "# Просмотрим количество пустых значений\r\n",
        "print(\"Количество пустых значений: \")\r\n",
        "print(df.isnull().sum())\r\n",
        "# Заполним пустые значения медианным значением каждого столбца\r\n",
        "df = df.fillna(df.median())\r\n",
        "print(\"Количество пустых значений после изменений: \")\r\n",
        "print(df.isnull().sum())\r\n",
        "# Остались категориальные атрибуты. Заполним их самым частым значением\r\n",
        "df = df.fillna(df.mode().iloc[0])\r\n",
        "print(\"Количество пустых значений после заполнения категориальных переменных: \")\r\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQDVN0YoMQEq"
      },
      "source": [
        "print(\"Чистые данные: \")\r\n",
        "print(df.describe(include=\"all\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shv2aKm2MQJb"
      },
      "source": [
        "# Проверим насколько сбалансированны классы\r\n",
        "df[\"BAD\"].value_counts().plot(kind=\"bar\")\r\n",
        "plt.title(\"Bad\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wySqUrYiMQOP"
      },
      "source": [
        "print(\"%f процентов заемщиков не выплатили кредит\"\r\n",
        "      % ((df.BAD[df.BAD == 1].count()/df.BAD.count())*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ayllSX3MQSy"
      },
      "source": [
        "# # Нормализую данные: привожу в вид от 0 до 1\r\n",
        "numeric_features = df.select_dtypes(include=[np.number])\r\n",
        "print(\"Численные атрибуты: \", numeric_features.columns.values)\r\n",
        "print(\"До нормализации: \")\r\n",
        "print(numeric_features.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JF80ecgMQY5"
      },
      "source": [
        "numeric_features_scaled = ((numeric_features - numeric_features.min()) /\r\n",
        "                           (numeric_features.max() - numeric_features.min()))\r\n",
        "print(\"После нормализации:\")\r\n",
        "print(numeric_features_scaled.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPFniizKMQhH"
      },
      "source": [
        "df[numeric_features.columns.values] = numeric_features_scaled[numeric_features.columns.values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcCnDyj-MQn2"
      },
      "source": [
        "print(\"Чистые и нормализованные данные:\")\r\n",
        "print(df.describe(include=\"all\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbk0ArZdMQuI"
      },
      "source": [
        "# Заменим категориальные атрибуты(JOB and REASON) на фиктивные значение 0 или 1\r\n",
        "df = pd.get_dummies(df, drop_first=True)\r\n",
        "print(\"Первые 5 наблюдений после замены на фиктивные значения: \")\r\n",
        "print(df.head())\r\n",
        "print(\"Количество наблюдений и атрибутов после замены: \", df.shape)\r\n",
        "print(\"Чистые и нормализованные данные c фиктивными значениями вместо категориальных:\")\r\n",
        "print(df.describe(include=\"all\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMprn6v2MQzL"
      },
      "source": [
        "# Проверим есть ли корреляция между атрибутами. Сохраним корреляционную матрицу в Excel-файле:\r\n",
        "corr = df.corr()\r\n",
        "corr.to_excel(\"../data/Correlations.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDHpP7dAMQ6F"
      },
      "source": [
        "# Просмотр корреляции между значениями не в Excel:\r\n",
        "triangle = corr.abs().where(np.tril(np.ones(corr.shape), k=-1).astype(np.bool))\r\n",
        "print(\"Самая сильная корреляция:\")\r\n",
        "print(triangle.stack().sort_values(ascending=False)[:7])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENrUOTUfMREG"
      },
      "source": [
        "# # Разделим на тренировочную и тестовую выборки\r\n",
        "# Сперва разделим данные на X (все атрибуты) и y (колонка BAD: то, что надо предсказать):\r\n",
        "y = df.BAD\r\n",
        "X = df.drop(\"BAD\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXaXK68-MRLY"
      },
      "source": [
        "# Теперь разделим данные на две части, на 70% данных будем обучать модель, 30% отложим для тестирования:\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\r\n",
        "# Параметр stratify гарантирует, что пропорции классов (20% невыплат) будут одинаковыми в тестовой и в учебной выборках)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6YSy1GdMRUh"
      },
      "source": [
        "# # Определяем оптимальные гиперпараметры\r\n",
        "# Создание классификатора:\r\n",
        "clsf = SVC(class_weight=\"balanced\", kernel=\"rbf\")\r\n",
        "# Выбор гиперпараметров: пробуем C от 0,5 до 5000 и gamma от 0,01 до 1:\r\n",
        "param_distributions = {\"C\": sp.stats.uniform(0.5, 5000), \"gamma\": sp.stats.uniform(0.01, 1)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqMpaqMEMyQD"
      },
      "source": [
        "# # Начинаем обучение модели:\r\n",
        "# Пробуем 40 разных сочетаний гиперпараметров, тестируем каждое сочетание 4 раза (перекрёстная проверка),\r\n",
        "# оцениваем по количеству правильно классифицированных наблюдений в обоих классах:\r\n",
        "random_search = RandomizedSearchCV(clsf, param_distributions=param_distributions,\r\n",
        "                                   n_iter=40, cv=4, scoring=\"balanced_accuracy\", n_jobs=-1)\r\n",
        "random_search.fit(X_train, y_train)\r\n",
        "# Сохранаяем оптимальную модель и смотрми на ее параметры:\r\n",
        "model = random_search.best_estimator_\r\n",
        "print(\"Оптимальные параметры: %s, оценка на учебных данных: %0.2f\"\r\n",
        "      % (random_search.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb3bR7kOMyVM"
      },
      "source": [
        "# Сохраним модель:\r\n",
        "filename = 'svc_model.sav'\r\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhqJEngmMyat"
      },
      "source": [
        "# # Оценка модели\r\n",
        "model = pickle.load(open(filename, 'rb'))\r\n",
        "y_pred = model.predict(X_test)\r\n",
        "\r\n",
        "print(\"Результат на тестовых данных: %f\" %\r\n",
        "      (100*metrics.balanced_accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOdED8rjM8Ns"
      },
      "source": [
        "# Посмотрим на конкретное количество наблюдений,\r\n",
        "# записанных классификатором в тот или иной класс, для этого посчитаем матрицу неточностей:\r\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzRxQFSUM8TN"
      },
      "source": [
        "print(\"Матрица неточностей:\")\r\n",
        "print(cnf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDb8cd3hMyg0"
      },
      "source": [
        "# Для наглядности можно показать матрицу на графике:\r\n",
        "sb.heatmap(cnf_matrix, annot=True, cmap=\"Blues\", fmt=\"g\",\r\n",
        "           xticklabels=[\"Выплата\", \"Невыплата\"], yticklabels=[\"Выплата\", \"Невыплата\"])\r\n",
        "plt.ylabel(\"Реальное значение\")\r\n",
        "plt.xlabel(\"Предсказанное значение\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}